import{_ as e,o as r,c as o,e as t}from"./app-IhAAo6dU.js";const i="/sas_prologue.png",n={},a=t('<p><img src="'+i+'" alt="prologue"></p><h2 id="what-is-signals-sorcery" tabindex="-1"><a class="header-anchor" href="#what-is-signals-sorcery" aria-hidden="true">#</a> What is Signals &amp; Sorcery?</h2><p>Signals &amp; Sorcery is a <strong>modern generative music performance platform</strong> that combines AI-powered clip generation with a DJ-inspired dual-deck workflow. Describe the sounds you want in natural language, preview them privately in your headphones, and push approved material to your audience - all in real-time.</p><p>The platform features hardware-level audio routing inspired by professional DJ setups: separate headphone (cue) and main outputs let you audition AI-generated clips privately before your audience hears them.</p><h2 id="who-is-this-for" tabindex="-1"><a class="header-anchor" href="#who-is-this-for" aria-hidden="true">#</a> Who is this for?</h2><ul><li><strong>Generative Music Performers</strong> who want to create and perform AI-generated music live</li><li><strong>Electronic Musicians</strong> looking for a new approach to live performance with AI assistance</li><li><strong>Live Coders &amp; Experimental Artists</strong> who want intuitive AI-driven music generation</li><li><strong>Streamers &amp; Content Creators</strong> who want to generate music in real-time while broadcasting</li><li><strong>Anyone</strong> who finds traditional live performance setups limiting and wants to explore generative approaches</li></ul><h2 id="how-does-it-work" tabindex="-1"><a class="header-anchor" href="#how-does-it-work" aria-hidden="true">#</a> How does it work?</h2><h3 id="core-technology" tabindex="-1"><a class="header-anchor" href="#core-technology" aria-hidden="true">#</a> Core Technology</h3><ul><li><strong>Native Audio Engine</strong>: Built on Tracktion Engine (C++) with JSON-RPC communication</li><li><strong>AI-Powered Generation</strong>: Uses AI providers (OpenAI, Groq, or Gemini) to interpret musical descriptions and generate MIDI</li><li><strong>Dual-Deck Architecture</strong>: Loop A (composition/preview) and Loop B (performance/audience) with independent routing</li><li><strong>DJ-Style Monitoring</strong>: Hardware-level support for headphone cue and main outputs</li><li><strong>Surge XT Integration</strong>: Automatically loads and configures synth patches based on sound descriptions</li></ul><h3 id="the-performance-workflow" tabindex="-1"><a class="header-anchor" href="#the-performance-workflow" aria-hidden="true">#</a> The Performance Workflow</h3><ol><li><strong>Generate</strong> - Describe a sound in natural language (&quot;dark sub bass&quot;, &quot;glitchy hi-hats&quot;)</li><li><strong>Preview</strong> - AI generates clips that play in your headphones (cue output)</li><li><strong>Refine</strong> - Iterate on the generation until you&#39;re satisfied</li><li><strong>Perform</strong> - Push approved clips to the audience (main output)</li></ol><h3 id="key-features" tabindex="-1"><a class="header-anchor" href="#key-features" aria-hidden="true">#</a> Key Features</h3><ul><li><strong>Text-to-Clip Generation</strong>: Describe sounds and get playable MIDI clips with configured synths</li><li><strong>Private Preview</strong>: Audition generated content in headphones before the audience hears it</li><li><strong>Seamless Transitions</strong>: Move material between decks for smooth live performances</li><li><strong>Multiple AI Providers</strong>: Choose between OpenAI, Groq, or Google Gemini</li><li><strong>Zero-Friction Setup</strong>: Automatic installation of synths and presets on first launch</li></ul><h2 id="current-limitations" tabindex="-1"><a class="header-anchor" href="#current-limitations" aria-hidden="true">#</a> Current Limitations</h2><ul><li><strong>macOS Only</strong>: Tested on M-series &amp; Intel chips (Windows/Linux not supported)</li><li><strong>Surge XT Dependency</strong>: Currently only works with Surge XT synthesizer</li><li><strong>MIDI-Focused</strong>: Designed for MIDI/synth-based production and performance</li></ul>',15),s=[a];function l(d,h){return r(),o("div",null,s)}const u=e(n,[["render",l],["__file","index.html.vue"]]);export{u as default};
